{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# we now use OpenAI to send requests\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78b8cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17ce3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for console formatting I use the Rich library\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8e3ff6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'programming', 'setup': '3 SQL statements walk into a NoSQL bar. Soon, they walk out', 'punchline': \"They couldn't find a table.\", 'id': 369}\n"
     ]
    }
   ],
   "source": [
    "# We are familiar with a standard API request\n",
    "# This is a public API that returns a random joke\n",
    "# The API developers have a very deterministic response even if random\n",
    "# Both sides program imperatively\n",
    "\n",
    "get_random_joke_internet = requests.get(\n",
    "    \"https://official-joke-api.appspot.com/random_joke\"\n",
    ")\n",
    "\n",
    "print(get_random_joke_internet.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1179b4c5-cd1f-4131-a876-4c9f3f38d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins:sk-proj-y-\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins:{openai_api_key[:10]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "797fe7b0-ad43-42d2-acf0-e4f309b112f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "print(f\"MODEL: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "378a0296-59a2-45c6-82eb-941344d3eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original prompt\n",
    "system_message = \"\"\"\n",
    "You are an assistant that is great at telling jokes.\n",
    "\"\"\"\n",
    "\n",
    "# Here is where we can do some prompt engineering - we are adding to the system message\n",
    "prompt_engineering = \"\"\"\n",
    "A joke worthy of publishing is a joke that has a rating of 8.5/10 or above.\n",
    "\n",
    "If the joke is worthy of publishing also include next: PUBLISH otherwise next: RETRY\n",
    "\n",
    "Here is an example of a joke worth of publishing:\n",
    "Supply the response in the following JSON format:\n",
    "{\"setup\": \"The setup of the joke\",\n",
    "\"punchline\": \"The punchline of the joke\",   \n",
    "\"rating\": \"9.0\",\n",
    "\"next\": \"PUBLISH\"\n",
    "}\n",
    "\n",
    "Remove all back ticks and other unnecessary characters and just print the JSON format and nothing else.\n",
    "\n",
    "Please ensure jokes are not repeated on retries\n",
    "\n",
    "Thank you.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "system_message += prompt_engineering\n",
    "\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Pythonistas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4d56a0f-2a3d-484d-9344-0efa6862aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a list of messages to pass to the LLM\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b3879b6-9a55-4fed-a18c-1ea2edfaf397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"setup\": \"Why do Python programmers prefer dark mode?\", \"punchline\": \"Because light attracts bugs!\", \"rating\": \"8.7\", \"next\": \"PUBLISH\"}\n"
     ]
    }
   ],
   "source": [
    "# We saw previously what is returned in the response object\n",
    "\n",
    "response = client.chat.completions.create(model=MODEL, messages=prompts)\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "output = response.choices[0].message.content.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ddd58",
   "metadata": {},
   "source": [
    "For the application, we create a state object so that we can track the state of the application - it is custom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2378ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\"next\": \"\", \"setup\": \"\", \"punchline\": \"\", \"rating\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b83b7094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"setup\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Why do Python programmers prefer dark mode?\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"punchline\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Because light attracts bugs!\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"rating\"</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"8.7\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"next\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"PUBLISH\"</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m\"setup\"\u001b[0m: \u001b[32m\"Why do Python programmers prefer dark mode?\"\u001b[0m, \u001b[32m\"punchline\"\u001b[0m: \u001b[32m\"Because light attracts bugs!\"\u001b[0m, \u001b[32m\"rating\"\u001b[0m: \n",
       "\u001b[32m\"8.7\"\u001b[0m, \u001b[32m\"next\"\u001b[0m: \u001b[32m\"PUBLISH\"\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We split the output to extract the JSON - there are better ways of getting structured output but this is for demo purposes\n",
    "\n",
    "# output_json = output.split(\"|\")\n",
    "# output_dict = json.loads(output_json[1])\n",
    "# print(type(output_dict))\n",
    "\n",
    "# console.print(output_dict)\n",
    "console.print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43271806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setup': 'Why do Python programmers prefer dark mode?', 'punchline': 'Because light attracts bugs!', 'rating': '8.7', 'next': 'PUBLISH'}\n"
     ]
    }
   ],
   "source": [
    "# We can update the state object for use in our app...\n",
    "result = json.loads(output)\n",
    "print(result)\n",
    "if result[\"next\"] == \"PUBLISH\":\n",
    "    state[\"next\"] = result[\"next\"]\n",
    "    state[\"setup\"] = result[\"setup\"]\n",
    "    state[\"rating\"] = result[\"rating\"]\n",
    "    state[\"punchline\"] = result[\"punchline\"]\n",
    "\n",
    "else:\n",
    "    state[\"next\"] = \"RETRY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ee3edbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">next: <span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">PUBLISH</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "next: \u001b[1;38;5;208mPUBLISH\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can extract the NEXT step from the Autonomous AI Agent.\n",
    "# This can then be used in a range of sofware design patterns for program flow.\n",
    "\n",
    "console.print(f\"next: [dark_orange bold]{state['next']}[/]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
