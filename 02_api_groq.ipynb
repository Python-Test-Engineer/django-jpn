{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d568515",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\", api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")\n",
    "model = (\"llama3-70b-8192\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a63309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client created: <openai.OpenAI object at 0x0000021BCA0ECD70>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Client created: {client}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78b8cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378a0296-59a2-45c6-82eb-941344d3eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original prompt\n",
    "system_message = \"\"\"\n",
    "You are an assistant that is great at telling jokes.\n",
    "\"\"\"\n",
    "\n",
    "# Here is where we can do some prompt engineering - we are adding to the system message\n",
    "prompt_engineering = \"\"\"\n",
    "A joke worthy of publishing is a joke that has a rating of 8.5/10 or above.\n",
    "\n",
    "If the joke is worthy of publishing also include next: PUBLISH otherwise next: RETRY\n",
    "\n",
    "Here is an example of a joke worth of publishing:\n",
    "Supply the response in the following JSON format:\n",
    "{\"setup\": \"The setup of the joke\",\n",
    "\"punchline\": \"The punchline of the joke\",   \n",
    "\"rating\": \"9.0\",\n",
    "\"next\": \"PUBLISH\"\n",
    "}\n",
    "\n",
    "Remove all back ticks and other unnecessary characters and just print the JSON format and nothing else.\n",
    "\n",
    "Please ensure jokes are not repeated on retries\n",
    "\n",
    "Thank you.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "system_message += prompt_engineering\n",
    "\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Pythonistas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d56a0f-2a3d-484d-9344-0efa6862aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a list of messages to pass to the LLM\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57565fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's fast-paced, technology-driven world. Here's why:\n",
      "\n",
      "1. **Speed and Efficiency**: Fast language models can process and analyze vast amounts of text data quickly, enabling applications to respond rapidly to user queries, generate text, or perform other tasks. This speed is essential in real-time applications, such as chatbots, virtual assistants, and language translation software.\n",
      "2. **Improved User Experience**: Fast language models enhance the user experience by providing swift and accurate responses. This is particularly important in applications where users expect instant answers, such as customer support chatbots, voice assistants, or language translation apps.\n",
      "3. **Scalability and Capacity**: Fast language models can handle large volumes of text data, making them ideal for applications that require processing massive amounts of information, such as text analysis, sentiment analysis, or entity recognition.\n",
      "4. **Real-time Processing**: Fast language models enable real-time processing, which is critical in applications like:\n",
      "\t* Sentiment analysis: Analyzing user comments or reviews in real-time to gauge public opinion.\n",
      "\t* Event detection: Detecting and responding to events, such as natural disasters or emergencies, as they unfold.\n",
      "\t* Live translation: Translating spoken language in real-time, facilitating communication across languages.\n",
      "5. **Competitive Advantage**: Organizations that leverage fast language models can gain a competitive edge by:\n",
      "\t* Responding quickly to customer inquiries, improving customer satisfaction.\n",
      "\t* Analyzing market trends and making data-driven decisions faster than competitors.\n",
      "\t* Developing innovative applications that utilize fast language models, such as smart home devices or virtual assistants.\n",
      "6. **Enhanced Research and Development**: Fast language models facilitate research and development in areas like:\n",
      "\t* Natural Language Processing (NLP): Enabling researchers to quickly test and refine new NLP models and algorithms.\n",
      "\t* Machine Learning: Allowing researchers to train and test machine learning models more efficiently, accelerating the development of new AI applications.\n",
      "7. **Cost Savings**: Fast language models can reduce computational costs by:\n",
      "\t* Minimizing the time required for text processing and analysis.\n",
      "\t* Reducing the need for manual annotation and labeling of data.\n",
      "8. **Broader Accessibility**: Fast language models can make language-related applications more accessible to a wider audience, including:\n",
      "\t* Language learners: Enabling language learners to practice conversational skills with virtual language exchange partners.\n",
      "\t* People with disabilities: Providing assistive technologies, such as speech-to-text or text-to-speech systems, that rely on fast language models.\n",
      "\n",
      "In summary, fast language models are essential for various applications, from improving user experience and scalability to driving competitive advantage and facilitating research and development. Their importance will only continue to grow as the demand for efficient and effective language processing increases.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
