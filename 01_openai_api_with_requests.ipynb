{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# we read our API keys from .env - I have a .env.sample for you, just rename to .env\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78b8cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1179b4c5-cd1f-4131-a876-4c9f3f38d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-y-\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:10]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a90e8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model selected: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# We select our model\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "print(f\"Model selected: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0949f018",
   "metadata": {},
   "source": [
    "For demo, we will create our own OpenAI request class but in future we will use the OpenAI library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1226148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are essentially making a POST request to one endpoint and we create a convenience Class to pass in prompts, temperature and model.\n",
    "\n",
    "# Temperature - The OpenAI API incorporates a hyperparameter known as temperature that affects the computation of token probabilities when generating output through the large language model. The temperature value ranges from 0 to 2, with lower values indicating greater determinism and higher values indicating more randomness.\n",
    "\n",
    "\n",
    "class MyCustomOpenAI:\n",
    "\n",
    "    def __init__(self, system_prompt=None, temperature=0.5, model=MODEL):\n",
    "\n",
    "        self.model_endpoint = \"https://api.openai.com/v1/chat/completions\"\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.system_prompt = system_prompt\n",
    "        self.api_key = openai_api_key\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "        }\n",
    "\n",
    "    def generate_text(self, prompt):\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "            \"temperature\": self.temperature,\n",
    "        }\n",
    "\n",
    "        # Use HTTP POST method from Requests library\n",
    "        response = requests.post(\n",
    "            url=self.model_endpoint, headers=self.headers, data=json.dumps(payload)\n",
    "        ).json()\n",
    "\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "548bb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an instance of MyCustomOpenAI and pass in a request\n",
    "\n",
    "client = MyCustomOpenAI(\n",
    "    model=MODEL,\n",
    "    system_prompt=\"You give concise answers to questions with no more than 100 characters\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "response = client.generate_text(\"What is Pydantic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39feb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-As9hvWv6ihbRnJIXu6VrfHejeqU7q', 'object': 'chat.completion', 'created': 1737470391, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Pydantic is a data validation and settings management library for Python.', 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 30, 'completion_tokens': 15, 'total_tokens': 45, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'service_tier': 'default', 'system_fingerprint': 'fp_72ed7ab54c'}\n"
     ]
    }
   ],
   "source": [
    "print(response)\n",
    "# print(response[\"choices\"][0])\n",
    "# print(response[\"choices\"][0][\"message\"])\n",
    "# print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "# print(response[\"choices\"][0][\"message\"][\"content\"].replace(\"\\n\\n\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8ee55",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
